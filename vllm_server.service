[Unit]
Description=vLLM OpenAI API Server
After=network.target

[Service]
User=root
Group=root

WorkingDirectory=/home/asuengai/RAG/RAG
EnvironmentFile=/home/asuengai/RAG/RAG/vllm.env

ExecStart=/home/asuengai/RAG/RAG/venv/bin/python3 -m vllm.entrypoints.openai.api_server \
  --model ${VLLM_MODEL} \
  --host ${VLLM_HOST} \
  --port ${VLLM_PORT} \
  --dtype float16 \
  --max-model-len ${VLLM_MAX_LEN} \
  --gpu-memory-utilization ${VLLM_GPU_UTIL} \
  --enforce-eager \
  --disable-cuda-graph

Restart=always
RestartSec=5
TimeoutStartSec=15min
KillMode=process

[Install]
WantedBy=multi-user.target
